# Story 2.3: Manual Data Import with Geographic Region Support

## Status
Approved

## Story
**As a** user,
**I want** to be able to import CSV data from external tools like Semrush, Ahrefs, and Google Keyword Planner into a project,
**so that** I can merge external keyword data with my AI-generated keywords and enrich them with search volumes, difficulty, and competition metrics.

## Acceptance Criteria
1. User can upload CSV files from external tools (Semrush, Ahrefs, Google Keyword Planner)
2. System automatically detects and maps common CSV column formats from different tools
3. User can manually map CSV columns to system fields if auto-detection fails
4. Imported keywords are merged with existing AI-generated keywords based on keyword text matching
5. New keywords from CSV that don't match existing ones are added to the keyword list
6. Geographic region context is maintained and validated during import
7. Tool-specific metrics are preserved in flexible data schema alongside common metrics
8. User receives clear feedback on import success/failure with detailed error reporting
9. Import process handles large CSV files efficiently with progress indicators
10. Imported data respects project ownership and authentication requirements

## Tasks / Subtasks
- [x] Task 0: Git workflow setup (Required before implementation)
  - [x] Create and checkout feature branch: `feature/2.3-manual-data-import`
  - [x] Verify branch is properly created and pushed to origin
  - [x] Document branch creation commit ID in Dev Agent Record
- [ ] Task 1: Create CSV parsing and validation service (AC: 1, 2, 8, 9)
  - [ ] Implement CSV parser supporting multiple file encodings (UTF-8, ISO-8859-1)
  - [ ] Create auto-detection for common external tool CSV formats
  - [ ] Add file size validation and chunked processing for large files
  - [ ] Implement progress tracking for CSV processing operations
  - [ ] Add comprehensive error handling and validation reporting
  - [ ] Create data sanitization to prevent CSV injection attacks
  - [ ] Commit with message: "feat: implement CSV parsing and validation service"
  - [ ] Document commit ID in Dev Agent Record
- [ ] Task 2: Implement external tool schema mapping (AC: 2, 3, 7)
  - [ ] Create schema definitions for Semrush CSV format
  - [ ] Create schema definitions for Ahrefs CSV format
  - [ ] Create schema definitions for Google Keyword Planner CSV format
  - [ ] Implement automatic column mapping based on header detection
  - [ ] Create manual column mapping interface for unknown formats
  - [ ] Add validation for mapped data types and value ranges
  - [ ] Preserve tool-specific metrics in external_tool_data JSONB field
  - [ ] Commit with message: "feat: implement external tool schema mapping"
  - [ ] Document commit ID in Dev Agent Record
- [ ] Task 3: Create keyword merging and conflict resolution (AC: 4, 5, 6)
  - [ ] Implement keyword matching algorithm (exact text match, case-insensitive)
  - [ ] Create merge strategy for conflicting metric values from different tools
  - [ ] Add geographic region validation and consistency checking
  - [ ] Implement new keyword insertion for unmatched CSV entries
  - [ ] Add conflict resolution UI for user decision making
  - [ ] Create audit trail for import changes and data sources
  - [ ] Commit with message: "feat: implement keyword merging and conflict resolution"
  - [ ] Document commit ID in Dev Agent Record
- [ ] Task 4: Create CSV import API endpoints (AC: 1, 6, 8, 10)
  - [ ] Implement POST /api/v1/projects/:id/keywords/import endpoint
  - [ ] Add file upload handling with multipart form support
  - [ ] Integrate CSV parsing service with API endpoints
  - [ ] Add authentication middleware and project ownership validation
  - [ ] Implement region context validation for imported data
  - [ ] Add comprehensive error response formatting
  - [ ] Create import status tracking and progress endpoints
  - [ ] Commit with message: "feat: implement CSV import API endpoints"
  - [ ] Document commit ID in Dev Agent Record
- [ ] Task 5: Create CSV import UI components (AC: 2, 3, 8, 9)
  - [ ] Create CSVUploadForm component with drag-and-drop file upload
  - [ ] Create ColumnMappingInterface for manual schema mapping
  - [ ] Create ImportPreview component showing data before final import
  - [ ] Create ImportProgress component with real-time status updates
  - [ ] Add custom error modals for import failures (no browser prompts)
  - [ ] Create ImportResults component showing success/failure summary
  - [ ] Add file format validation and user guidance
  - [ ] Commit with message: "feat: implement CSV import UI components"
  - [ ] Document commit ID in Dev Agent Record
- [ ] Task 6: Integrate import workflow with sequential flow (AC: 4, 5, 7)
  - [ ] Add CSV import option to keyword generation workflow
  - [ ] Update keyword data table to show imported vs AI-generated keywords
  - [ ] Add tool source indicators in keyword display
  - [ ] Create import history and data lineage tracking
  - [ ] Update sequential workflow navigation to include import step
  - [ ] Add import validation within geographic region context
  - [ ] Commit with message: "feat: integrate CSV import with sequential workflow"
  - [ ] Document commit ID in Dev Agent Record
- [ ] Task 7: Testing (All ACs)
  - [ ] Write unit tests for CSV parsing service with various file formats
  - [ ] Write unit tests for external tool schema mapping
  - [ ] Write unit tests for keyword merging algorithms
  - [ ] Write unit tests for CSV import API endpoints
  - [ ] Write unit tests for CSV import UI components
  - [ ] Write E2E tests for complete CSV import workflow
  - [ ] Test large file handling and performance
  - [ ] Test integration with geographic region context
  - [ ] Test error handling and recovery scenarios
  - [ ] Commit with message: "test: add comprehensive CSV import test coverage"
  - [ ] Document commit ID in Dev Agent Record

## Dev Notes

**Epic 2 Completion:**
- **Story 2.1** ✅ Content ingestion foundation
- **Story 2.2** ✅ AI keyword generation
- **Story 2.2.5** ✅ Sequential workflow with geographic regions and flexible schema
- **Story 2.3** 📋 CSV import (this story) - Enhanced with new architecture

**Story 2.2.5 Integration:**
Building on the completed sequential workflow and geographic region support:
- **Flexible Schema:** Use new external_tool_data JSONB field for tool-specific metrics
- **Geographic Regions:** Validate imported data matches project's geographic region
- **Data Table Integration:** Imported keywords display in new sortable data table
- **Sequential Workflow:** CSV import becomes part of page-by-page processing flow

**External Tool Support:**
Based on core workflow requirements and common SEO tools:

**Semrush CSV Format:**
- Keyword, Search Volume, KD (Keyword Difficulty), CPC, Competition Level, Results, Intent, Position, Previous Position, Change, Serp Features

**Ahrefs CSV Format:**
- Keyword, Search Volume, Keyword Difficulty, CPC, Parent Topic, Traffic Potential, Return Rate, Clicks

**Google Keyword Planner CSV Format:**
- Keyword, Avg. Monthly Searches, Competition, Competition (indexed value), Top of page bid (low range), Top of page bid (high range)

**Schema Mapping Strategy:**
- **Common Metrics:** Volume → Search Volume/Avg. Monthly Searches, Difficulty → KD/Keyword Difficulty
- **Tool-Specific Preservation:** All unique tool metrics stored in external_tool_data JSONB
- **Conflict Resolution:** When multiple tools provide same metric, allow user choice or use most recent

**Geographic Region Integration:**
- **Import Validation:** Ensure imported CSV data matches project's default region
- **Region Context:** All imported keywords inherit project's geographic region
- **Data Consistency:** Prevent mixing UK Semrush data with US Keyword Planner data

**Keyword Merging Algorithm:**
1. **Exact Match:** Case-insensitive string comparison on keyword text
2. **Merge Strategy:** Combine AI-generated keywords with external tool metrics
3. **New Keywords:** Add CSV keywords that don't match existing AI-generated ones
4. **Conflict Resolution:** UI for user decisions when metrics conflict between sources
5. **Audit Trail:** Track data source and import timestamp for each metric

**Database Schema Integration:**
Uses new flexible schema from Story 2.2.5:
```sql
-- Keywords table now includes:
region VARCHAR(5)              -- Geographic region context
external_tool_data JSONB       -- Tool-specific metrics
tool_source VARCHAR(50)        -- Semrush, Ahrefs, Keyword Planner, AI Generated
```

**CSV Processing Architecture:**
- **File Upload:** Multipart form with drag-and-drop interface
- **Chunked Processing:** Handle large files (>10MB) with progress tracking
- **Error Recovery:** Detailed error reporting with line-by-line validation results
- **Preview Mode:** Show mapped data before final import for user validation

**Performance Considerations:**
- **Streaming Processing:** Process large CSV files in chunks to avoid memory issues
- **Background Jobs:** Consider queue system for very large imports
- **Progress Tracking:** Real-time progress updates during processing
- **Database Optimization:** Batch inserts for large keyword datasets

**Security Considerations:**
- **CSV Injection Prevention:** Sanitize all imported data to prevent formula injection
- **File Validation:** Restrict file types and sizes to prevent abuse
- **Project Ownership:** Users can only import to their tenant's projects
- **Region Validation:** Ensure imported data matches project region context
- **Authentication Required:** All import operations require valid session

**Tech Stack Requirements:**
- Use TypeScript for all development [Source: architecture/tech-stack.md]
- Use Zod for CSV data validation and schema mapping
- Use Prisma for database operations with JSONB field updates
- Use Tailwind CSS for import UI components
- Consider Papa Parse or similar library for robust CSV parsing

**Environment Configuration:**
- **File Upload Limits:** Configure maximum CSV file size (e.g., 50MB)
- **Processing Timeouts:** Set appropriate timeouts for large file processing
- **Dev Server Port:** Continue using port 3060 for consistency
- **Database:** Continue using flowseo_dev database with existing schema
- **Authentication:** Reuse existing JWT_SECRET and session configuration

**UX Standards (Custom Modals):**
- **Custom Modal Dialogs:** No browser default prompts for import errors or confirmations
- **Loading States:** Clear progress indicators during CSV processing
- **Professional UI:** Consistent styling with existing app design
- **Drag-and-Drop:** Modern file upload interface with visual feedback
- **Error Reporting:** Detailed, actionable error messages with line numbers

**Integration with Core Workflow:**
Implements the CSV import stages from keyword research workflow [Source: architecture/core-workflows.md]:
1. User generates keywords with AI (Stories 2.1, 2.2) ✅
2. User copies keywords to external tools → gets CSV export
3. User imports CSV data (this story) ✅
4. System updates existing keywords and adds new ones ✅
5. User sees enriched keyword list with external tool metrics ✅

**File Locations:**
Following Next.js structure from previous stories:
- API routes: `/src/app/api/v1/projects/[id]/keywords/import/` directory
- CSV service: `/src/lib/services/csvParser.ts`, `/src/lib/services/externalToolMapper.ts`
- Components: `/src/components/` directory (CSVUploadForm, ColumnMappingInterface, ImportProgress)
- UI components: `/src/components/ui/` directory (FileUpload, ProgressBar, ImportResults)
- Import pages: Extension of existing `/src/app/projects/[id]/keywords/page.tsx`
- E2E tests: `/tests/csv-import.spec.ts`
- Unit tests: Colocated with components and services

**Integration with Sequential Workflow:**
Building on Story 2.2.5's sequential workflow:
- CSV import becomes optional step in page-by-page processing
- Import status tracked alongside page analysis status
- Geographic region context maintained throughout import process
- Imported data displays in new sortable data table with tool source indicators

**Project Structure Notes:**
Maintains existing Next.js structure while adding CSV processing capabilities. Manual data import integrates cleanly with established authentication, project management, geographic regions, and sequential workflow patterns.

### Testing
**Testing Standards from Architecture:**
- Use Playwright for end-to-end testing [Source: architecture/tech-stack.md]
- All tests must pass for story completion [Source: architecture/coding-standards.md]
- Follow established testing patterns from previous stories
- Test CSV parsing with various external tool formats
- Test large file handling and performance scenarios
- Test geographic region validation and consistency
- Test keyword merging algorithms with edge cases
- Test integration with sequential workflow from Story 2.2.5

**Git & Documentation Standards:**
- Feature branch: `feature/2.3-manual-data-import`
- Conventional commit format with Claude Code attribution
- Complete Dev Agent Record with commit hashes and quality gates
- Zero TypeScript/lint errors required before completion

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-09-19 | 1.0 | Initial manual data import story for Epic 2 completion with geographic region integration | Bob (Scrum Master) |

## Dev Agent Record
*This section will be populated by the development agent during implementation*

### Agent Model Used
*To be filled by dev agent*

### Debug Log References
- TypeScript compilation: `pnpm run type-check` - ✅/❌ [actual status]
- Linting: `pnpm run lint` - ✅/❌ [actual status]
- Build: `pnpm run build` - ✅/❌ [actual status]
- Tests: `pnpm run test` - ✅/❌ [actual status]

### Git Commits Created During This Session
**MANDATORY:** All commit IDs must be documented with conventional commit messages
- Branch creation: `26fc25c387528d9873c9e03b14b412b700a1b2fe` - Initial branch setup
- Task 1: `[hash]` - feat: implement CSV parsing and validation service
- Task 2: `[hash]` - feat: implement external tool schema mapping
- Task 3: `[hash]` - feat: implement keyword merging and conflict resolution
- Task 4: `[hash]` - feat: implement CSV import API endpoints
- Task 5: `[hash]` - feat: implement CSV import UI components
- Task 6: `[hash]` - feat: integrate CSV import with sequential workflow
- Task 7: `[hash]` - test: add comprehensive CSV import test coverage

### Completion Notes List
*To be filled by dev agent*

### File List
**New Files Created:**
*To be filled by dev agent*

**Modified Files:**
*To be filled by dev agent*

## QA Results
*Results from QA Agent review will be populated here*